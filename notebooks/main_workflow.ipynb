{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e256e51b-41fd-4d52-bb9d-7037115ff82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks/main_workflow.ipynb (converted to .py for versioning, run in Jupyter)\n",
    "from agents.rag_agent import answer_with_rag\n",
    "from agents.web_agent import search_web\n",
    "from agents.summarizer_agent import summarize_text\n",
    "from agents.email_agent import send_email\n",
    "\n",
    "# === USER QUERY ===\n",
    "query = \"A 12-year-old child is making careless mistakes in schoolwork and struggles to maintain attention. What might be the issue?\"\n",
    "\n",
    "# === STEP 1: Use RAG Agent ===\n",
    "rag_output = answer_with_rag(query)\n",
    "print(\"\\n--- RAG Agent Output ---\\n\")\n",
    "print(rag_output)\n",
    "\n",
    "# === STEP 2: Use Web Agent ===\n",
    "web_output = search_web(rag_output)\n",
    "print(\"\\n--- Web Search Output ---\\n\")\n",
    "print(web_output)\n",
    "\n",
    "# === STEP 3: Use Summarizer Agent ===\n",
    "combined = f\"RAG Output:\\n{rag_output}\\n\\nWeb Results:\\n{web_output}\"\n",
    "summary = summarize_text(combined)\n",
    "print(\"\\n--- Summary for Email ---\\n\")\n",
    "print(summary)\n",
    "\n",
    "# === STEP 4: Use Email Agent ===\n",
    "send_email(\"Child Mental Health Assessment Summary\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42c93b10-5940-49a2-ba53-c74872f14534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Go one level up to include the project root\n",
    "sys.path.append(os.path.abspath(\"..\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d4c8b6-6721-4cd4-b15d-cd534e5f8aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langgraph faiss-cpu duckduckgo-search unstructured pypdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2d90a1-cd9d-4460-9046-be7abadc773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8f3f02-5624-45cb-bc10-4e29e5bed784",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542c7705-ed24-4f94-932f-ce16e873d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pymupdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57cb1a4-df1b-4a5b-a109-2f2777a211a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af4c92b-df47-43a7-a81b-e650661af6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.rag_agent import build_rag_agent\n",
    "from agents.web_agent import search_web\n",
    "from agents.summarizer_agent import summarize_text\n",
    "from agents.rag_agent import build_rag_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cb64cb-9fe3-48cf-acf5-ab33aef64298",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4941f712-059f-425e-b4d2-b532603c184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.rag_agent import build_rag_agent\n",
    "from agents.web_agent import search_web\n",
    "from agents.summarizer_agent import summarize_text\n",
    "from agents.email_agent import send_email\n",
    "from agents.doctor_search_agent import search_doctor\n",
    "from config import SENDER_NAME\n",
    "import time\n",
    "\n",
    "sender_name = SENDER_NAME\n",
    "# === Build RAG Once ===\n",
    "rag_chain = build_rag_agent()  # ✅ Only builds once\n",
    "\n",
    "\n",
    "# === USER QUERY ===\n",
    "query = \"A 12-year-old child is making careless mistakes in schoolwork and struggles to maintain attention. What might be the issue?\"\n",
    "recipient_name = input(\"Enter recipient's name: \")\n",
    "recipient_email = input(\"Enter recipient's email: \")\n",
    "location = input(\"Enter city or pin code to search for doctors nearby: \")\n",
    "# === STEP 1: Use RAG Agent ===\n",
    "rag_output = rag_chain.invoke(query)\n",
    "print(\"\\n--- RAG Agent Output ---\\n\")\n",
    "print(rag_output)\n",
    "\n",
    "# === STEP 2: Use Web Agent ===\n",
    "time.sleep(10)  # prevent DuckDuckGo rate-limiting\n",
    "web_output = search_web(rag_output[\"result\"])  # ✅ correct\n",
    "\n",
    "print(\"\\n--- Web Search Output ---\\n\")\n",
    "print(web_output)\n",
    "\n",
    "# === STEP 3: Use Summarizer Agent ===\n",
    "combined = f\"RAG Output:\\n{rag_output}\\n\\nWeb Results:\\n{web_output}\"\n",
    "summary = summarize_text(combined)\n",
    "#print(\"\\n--- Summary for Email ---\\n\")\n",
    "# print(summary)\n",
    "\n",
    "# === STEP 4: Collect Email Info ===\n",
    "# recipient_name = input(\"Enter recipient's name: \")\n",
    "# recipient_email = input(\"Enter recipient's email: \")\n",
    "\n",
    "# Personalize summary\n",
    "personalized_summary = summary.replace(\"[Recipient]\", recipient_name).replace(\"[Your Name]\", sender_name)\n",
    "\n",
    "# === STEP 5: Follow-up RAG for Doctor Type ===\n",
    "followup_query = f\"What type of doctor should be consulted for this: {rag_output['result']}\"\n",
    "doctor_type = rag_chain.invoke(followup_query)[\"result\"].strip()\n",
    "\n",
    "#doctor_type = answer_with_rag(f\"What type of doctor should be consulted for this: {rag_output}\").strip()\n",
    "\n",
    "# === STEP 6: Ask for Location and Search Doctor ===\n",
    "# location = input(\"Enter city or pin code to search for doctors nearby: \")\n",
    "doctor_info = search_doctor(doctor_type, location)\n",
    "\n",
    "# === STEP 7: Final Email Body ===\n",
    "final_email_body = f\"{personalized_summary}\\n\\n--- Doctor Recommendation ---\\n{doctor_info}\"\n",
    "\n",
    "# === STEP 8: Send Final Email ===\n",
    "send_email(\"Child Mental Health Assessment Summary & Doctor Recommendation\", final_email_body, recipient_email)\n",
    "print(\"\\n--- Summary for Email ---\\n\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d03cced-1f4b-4bda-ab63-3bb4d241c486",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rag_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3503b725-9fe2-45fc-9019-6f12896a23cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0afd03-f343-4b8d-9443-fca02c91854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install duckduckgo-search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d382e42-79c1-4098-924b-2821884ed901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.rag_agent import build_rag_agent\n",
    "from agents.web_agent import search_web\n",
    "from agents.summarizer_agent import summarize_text\n",
    "from agents.email_agent import send_email\n",
    "from agents.doctor_search_agent import search_doctor\n",
    "from config import SENDER_NAME\n",
    "import time\n",
    "\n",
    "sender_name = SENDER_NAME\n",
    "# === Build RAG Once ===\n",
    "rag_chain = build_rag_agent()  # ✅ Only builds once\n",
    "\n",
    "\n",
    "# === USER QUERY ===\n",
    "query = \"A 12-year-old child is making careless mistakes in schoolwork and struggles to maintain attention. What might be the issue?\"\n",
    "recipient_name = input(\"Enter recipient's name: \")\n",
    "recipient_email = input(\"Enter recipient's email: \")\n",
    "location = input(\"Enter city or pin code to search for doctors nearby: \")\n",
    "# === STEP 1: Use RAG Agent ===\n",
    "rag_output = rag_chain.invoke(query)\n",
    "print(\"\\n--- RAG Agent Output ---\\n\")\n",
    "print(rag_output)\n",
    "\n",
    "# === STEP 2: Use Web Agent ===\n",
    "  # prevent DuckDuckGo rate-limiting\n",
    "web_output = search_web(rag_output[\"result\"])  # ✅ correct\n",
    "\n",
    "print(\"\\n--- Web Search Output ---\\n\")\n",
    "print(web_output)\n",
    "\n",
    "# === STEP 3: Use Summarizer Agent ===\n",
    "combined = f\"RAG Output:\\n{rag_output}\\n\\nWeb Results:\\n{web_output}\"\n",
    "summary = summarize_text(combined)\n",
    "\n",
    "# === STEP 4: Collect Email Info ===\n",
    "\n",
    "# Personalize summary\n",
    "personalized_summary = f\"Dear {recipient_name},\\n\\n\" + summary.replace(\"[Your Name]\", sender_name)\n",
    "\n",
    "# === STEP 5: Use RAG to get only doctor specialties (clean & structured) ===\n",
    "followup_query = (\n",
    "    \"From the earlier analysis, list only the doctor specialties or professional roles required to treat this child. \"\n",
    "    \"Return them as a comma-separated list only. Do not include explanations.\"\n",
    ")\n",
    "doctor_titles = rag_chain.invoke(followup_query)[\"result\"].strip()\n",
    "\n",
    "# Optional retry if the output is a sentence\n",
    "if \".\" in doctor_titles or len(doctor_titles.split()) > 15:\n",
    "    followup_query_retry = (\n",
    "        \"List only the doctor types (comma-separated, no sentence) that should treat a child with these symptoms.\"\n",
    "    )\n",
    "    doctor_titles = rag_chain.invoke(followup_query_retry)[\"result\"].strip()\n",
    "\n",
    "print(\"\\n--- Doctor Specialties Identified ---\\n\")\n",
    "print(doctor_titles)\n",
    "\n",
    "# === STEP 6: Use doctor_search_agent with the identified titles ===\n",
    "doctor_info_links = search_doctor(doctor_titles, location)\n",
    "\n",
    "# === STEP 7: Final Email Body ===\n",
    "final_email_body = f\"\"\"{personalized_summary}\n",
    "\n",
    "--- Doctor Recommendation ---\n",
    "Specialist(s) recommended: {doctor_titles}\n",
    "\n",
    "{doctor_info_links}\n",
    "\"\"\"\n",
    "\n",
    "# === STEP 8: Send Final Email ===\n",
    "send_email(\"Child Mental Health Assessment Summary & Doctor Recommendation\", final_email_body, recipient_email)\n",
    "print(\"\\n--- Summary for Email ---\\n\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae8c28c-4bff-484e-aaac-0e1f26e600ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "##new\n",
    "from agents.rag_agent import build_rag_agent\n",
    "from agents.web_agent import search_web\n",
    "from agents.summarizer_agent import summarize_text\n",
    "from agents.email_agent import send_email\n",
    "from agents.doctor_search_agent import search_doctor\n",
    "from config import SENDER_NAME\n",
    "import time\n",
    "\n",
    "sender_name = SENDER_NAME\n",
    "\n",
    "# === Build RAG Once ===\n",
    "rag_chain = build_rag_agent()  # ✅ Only builds once\n",
    "\n",
    "# === USER INPUT ===\n",
    "recipient_name = input(\"Enter recipient's name: \")\n",
    "recipient_email = input(\"Enter recipient's email: \")\n",
    "location = input(\"Enter city or pin code to search for doctors nearby: \")\n",
    "\n",
    "# === STEP 1: Use RAG Agent (Single Call for Diagnosis + Doctors) ===\n",
    "combined_query = (\n",
    "    \"A 12-year-old child is making careless mistakes in schoolwork and struggles to maintain attention.\\n\"\n",
    "    \"What might be the issue?\\n\"\n",
    "    \"Also, based on your analysis, list the doctor specialties (comma-separated only, no explanation) \"\n",
    "    \"who should be consulted for this case.\"\n",
    ")\n",
    "rag_response = rag_chain.invoke(combined_query)[\"result\"].strip()\n",
    "\n",
    "# === STEP 2: Parse Diagnosis and Doctor Titles ===\n",
    "if \"\\n\\n\" in rag_response:\n",
    "    diagnosis_part, doctor_titles = rag_response.split(\"\\n\\n\", 1)\n",
    "else:\n",
    "    lines = rag_response.splitlines()\n",
    "    diagnosis_part = \"\\n\".join(lines[:-1])\n",
    "    doctor_titles = lines[-1]\n",
    "\n",
    "diagnosis = diagnosis_part.strip()\n",
    "doctor_titles = doctor_titles.strip().rstrip(\".\")\n",
    "\n",
    "print(\"\\n--- Diagnosis ---\\n\")\n",
    "print(diagnosis)\n",
    "print(\"\\n--- Doctor Specialties Identified ---\\n\")\n",
    "print(doctor_titles)\n",
    "\n",
    "# === STEP 3: Use Web Agent (Optional) ===\n",
    "web_output = search_web(diagnosis)\n",
    "\n",
    "print(\"\\n--- Web Search Output ---\\n\")\n",
    "print(web_output)\n",
    "\n",
    "# === STEP 4: Summarize ===\n",
    "combined = f\"Diagnosis:\\n{diagnosis}\\n\\nWeb Results:\\n{web_output}\"\n",
    "summary = summarize_text(combined)\n",
    "\n",
    "# === STEP 5: Personalize Summary ===\n",
    "personalized_summary = f\"Dear {recipient_name},\\n\\n\" + summary.replace(\"[Your Name]\", sender_name)\n",
    "\n",
    "# === STEP 6: Get Doctor Info ===\n",
    "doctor_info_links = search_doctor(doctor_titles, location)\n",
    "\n",
    "# === STEP 7: Final Email Body ===\n",
    "final_email_body = f\"\"\"{personalized_summary}\n",
    "\n",
    "--- Doctor Recommendation ---\n",
    "Specialist(s) recommended: {doctor_titles}\n",
    "\n",
    "{doctor_info_links}\n",
    "\"\"\"\n",
    "\n",
    "# === STEP 8: Send Final Email ===\n",
    "send_email(\"Child Mental Health Assessment Summary & Doctor Recommendation\", final_email_body, recipient_email)\n",
    "print(\"\\n--- Summary for Email ---\\n\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2b5b65-2be1-4b72-be88-804288a28464",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install beautifulsoup4 requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708208a3-de97-42cf-9f84-6cd6d37c8c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import agents.doctor_search_agent\n",
    "importlib.reload(agents.doctor_search_agent)\n",
    "\n",
    "from agents.doctor_search_agent import get_doctor_specialty, search_doctor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508ba7a7-e305-495b-97cc-072c65bb2d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Proper run this firt in the morning\n",
    "from agents.rag_agent import build_rag_agent\n",
    "from agents.web_agent import search_web\n",
    "from agents.summarizer_agent import summarize_text\n",
    "from agents.email_agent import send_email\n",
    "from agents.doctor_search_agent import get_doctor_specialty, search_doctor, normalize_roles\n",
    "\n",
    "from config import SENDER_NAME\n",
    "\n",
    "sender_name = SENDER_NAME\n",
    "\n",
    "# === Build RAG Once ===\n",
    "rag_chain = build_rag_agent()\n",
    "\n",
    "# === USER INPUT ===\n",
    "recipient_name = input(\"Enter recipient's name: \")\n",
    "recipient_email = input(\"Enter recipient's email: \")\n",
    "location = input(\"Enter city or pin code to search for doctors nearby: \")\n",
    "\n",
    "# === STEP 1: Use RAG Agent for Diagnosis ===\n",
    "query = (\n",
    "    \"A 12-year-old child is making careless mistakes in schoolwork and struggles to maintain attention. \"\n",
    "    \"What might be the issue?\"\n",
    ")\n",
    "rag_response = rag_chain.invoke(query)[\"result\"]\n",
    "diagnosis = rag_response.strip()\n",
    "\n",
    "print(\"\\n--- Diagnosis ---\\n\")\n",
    "print(diagnosis)\n",
    "# === STEP 2: Get Doctor Specialties (RAG Follow-up) ===\n",
    "specialties = get_doctor_specialty(diagnosis, rag_chain)\n",
    "print(\"\\n--- Doctor Specialties Identified ---\\n\")\n",
    "print(specialties)\n",
    "print(\"🛠️ DEBUG: Helper functions loaded\")\n",
    "\n",
    "# === STEP 3: Web Search (Optional) ===\n",
    "web_output = search_web(diagnosis)\n",
    "print(\"\\n--- Web Search Output ---\\n\")\n",
    "print(web_output)\n",
    "\n",
    "# === STEP 4: Summarize ===\n",
    "combined = f\"Diagnosis:\\n{diagnosis}\\n\\nWeb Results:\\n{web_output}\"\n",
    "summary = summarize_text(combined)\n",
    "\n",
    "# === STEP 5: Personalize Summary ===\n",
    "personalized_summary = f\"Dear {recipient_name},\\n\\n\" + summary.replace(\"[Your Name]\", sender_name)\n",
    "\n",
    "# === STEP 6: Normalize & Search for Doctors ===\n",
    "normalized_specialties = normalize_roles(specialties)\n",
    "print(\"\\n--- Normalized Doctor Specialties for Practo ---\\n\")\n",
    "print(normalized_specialties)\n",
    "\n",
    "doctor_info_links = search_doctor(\", \".join(normalized_specialties), location)\n",
    "\n",
    "\n",
    "\n",
    "# === STEP 7: Final Email Body ===\n",
    "final_email_body = f\"\"\"{personalized_summary}\n",
    "\n",
    "--- Doctor Recommendation ---\n",
    "Specialist(s) recommended: {', '.join(specialties)}\n",
    "\n",
    "{doctor_info_links}\n",
    "\"\"\"\n",
    "\n",
    "# === STEP 8: Send Email ===\n",
    "send_email(\"Child Mental Health Assessment Summary & Doctor Recommendation\", final_email_body, recipient_email)\n",
    "\n",
    "# === Optional Preview ===\n",
    "print(\"\\n✅ Email Sent! --- Summary Preview Below ---\\n\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b62d84-f16b-49e6-a984-f1a22d7896e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import agents.doctor_search_agent as dsa\n",
    "\n",
    "print(dir(dsa))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddae854-a70b-4a9f-b0b1-2833c91b18dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import agents.doctor_search_agent as dsa\n",
    "importlib.reload(dsa)\n",
    "print(dir(dsa))  # Make sure you see 'get_doctor_specialty'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeab6b27-9e52-42e3-89a1-c1cd31130b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "from agents.rag_agent import build_rag_agent\n",
    "from agents.web_agent import search_web\n",
    "from agents.summarizer_agent import summarize_text\n",
    "from agents.email_agent import send_email\n",
    "from config import SENDER_NAME\n",
    "\n",
    "# --- Global cache for RAG ---\n",
    "rag_chain = build_rag_agent()\n",
    "\n",
    "# --- INPUT ---\n",
    "recipient_name = input(\"Enter recipient's name: \")\n",
    "recipient_email = input(\"Enter recipient's email: \")\n",
    "location = input(\"Enter city or pin code to search for doctors nearby: \")\n",
    "\n",
    "# --- STEP 1: Diagnosis via RAG ---\n",
    "query = (\n",
    "    \"A 12-year-old child is making careless mistakes in schoolwork and struggles to maintain attention. \"\n",
    "    \"What might be the issue?\"\n",
    ")\n",
    "rag_response = rag_chain.invoke(query)[\"result\"]\n",
    "diagnosis = rag_response.strip()\n",
    "print(\"\\n--- Diagnosis ---\\n\")\n",
    "print(diagnosis)\n",
    "\n",
    "# --- STEP 2: Extract Doctor Roles (from same chain) ---\n",
    "followup_query = (\n",
    "    \"List only the doctor types (e.g., Pediatrician, Child Psychologist) to treat this child. \"\n",
    "    \"Return as comma-separated values only with no explanation.\"\n",
    ")\n",
    "doctor_raw = rag_chain.invoke(followup_query)[\"result\"].strip()\n",
    "\n",
    "# Cleanup roles\n",
    "if \".\" in doctor_raw or len(doctor_raw.split()) > 20:\n",
    "    retry_query = \"List doctor types like Pediatrician, Neurologist. No explanation. Comma-separated.\"\n",
    "    doctor_raw = rag_chain.invoke(retry_query)[\"result\"].strip()\n",
    "\n",
    "specialties = [s.strip() for s in re.split(r\",|and\", doctor_raw) if s.strip()]\n",
    "print(\"\\n--- Doctor Specialties Identified ---\\n\")\n",
    "print(specialties)\n",
    "\n",
    "# --- STEP 3: Web Search ---\n",
    "web_output = search_web(diagnosis)\n",
    "print(\"\\n--- Web Search Output ---\\n\")\n",
    "print(web_output)\n",
    "\n",
    "# --- STEP 4: Summarize ---\n",
    "combined = f\"Diagnosis:\\n{diagnosis}\\n\\nWeb Results:\\n{web_output}\"\n",
    "summary = summarize_text(combined)\n",
    "\n",
    "# --- STEP 5: Personalize ---\n",
    "personalized_summary = f\"Dear {recipient_name},\\n\\n\" + summary.replace(\"[Your Name]\", SENDER_NAME)\n",
    "\n",
    "# --- STEP 6: Doctor Lookup ---\n",
    "def search_doctor(doctor_types, location):\n",
    "    roles = [r.strip() for r in doctor_types.split(\",\")]\n",
    "    city = location.strip().replace(\" \", \"-\").lower()\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "    output = \"\"\n",
    "    for role in roles[:2]:  # Limit to 2 roles for speed\n",
    "        q = quote(role)\n",
    "        url = f\"https://www.practo.com/{city}/doctors?specialization={q}\"\n",
    "        try:\n",
    "            r = requests.get(url, headers=headers, timeout=5)\n",
    "            soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "            cards = soup.select(\"div.card\")[:3]\n",
    "\n",
    "            if not cards:\n",
    "                output += f\"\\n❌ No {role} found in {location.title()}. [Search manually]({url})\\n\"\n",
    "                continue\n",
    "\n",
    "            output += f\"\\n🔍 Top {role}s in {location.title()}:\\n\"\n",
    "            for card in cards:\n",
    "                name = card.select_one(\"h2\")\n",
    "                spec = card.select_one(\".u-color--gray-dark\")\n",
    "                clinic = card.select_one(\".clinic-card .u-bold\")\n",
    "\n",
    "                output += f\"- {name.text.strip() if name else 'N/A'} ({spec.text.strip() if spec else role}) – {clinic.text.strip() if clinic else 'Unknown Clinic'}\\n\"\n",
    "        except Exception as e:\n",
    "            output += f\"\\n❌ Error for {role}: {e}\\n\"\n",
    "\n",
    "    return output\n",
    "\n",
    "# --- STEP 7: Doctor Search ---\n",
    "doctor_links = search_doctor(\", \".join(specialties), location)\n",
    "\n",
    "# --- STEP 8: Compose Email ---\n",
    "final_email = f\"\"\"{personalized_summary}\n",
    "\n",
    "--- Doctor Recommendation ---\n",
    "Specialist(s) recommended: {', '.join(specialties)}\n",
    "\n",
    "{doctor_links}\n",
    "\"\"\"\n",
    "\n",
    "# --- STEP 9: Send Email ---\n",
    "send_email(\"Child Mental Health Assessment Summary & Doctor Recommendation\", final_email, recipient_email)\n",
    "\n",
    "# --- Preview ---\n",
    "print(\"\\n✅ Email Sent! --- Summary Preview Below ---\\n\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e9d938-1847-4f19-ac4d-7cdf4ade8165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8046f007-b4a9-476f-8f39-6d9101a0ffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from agents.rag_agent import build_rag_agent\n",
    "from agents.web_agent import search_web\n",
    "from agents.summarizer_agent import summarize_text\n",
    "from agents.email_agent import send_email\n",
    "from agents.doctor_search_agent import get_doctor_specialty, search_doctor, normalize_roles\n",
    "from config import SENDER_NAME\n",
    "from agents.doctor_search_agent import search_multiple_doctors\n",
    "\n",
    "def log_time(label, start_time):\n",
    "    print(f\"⏱️ {label} took {time.time() - start_time:.2f} seconds\\n\")\n",
    "\n",
    "def main():\n",
    "    sender_name = SENDER_NAME\n",
    "\n",
    "    # === Build RAG Once ===\n",
    "    start = time.time()\n",
    "    rag_chain = build_rag_agent()\n",
    "    log_time(\"Build RAG Agent\", start)\n",
    "\n",
    "    # === USER INPUT ===\n",
    "    recipient_name = input(\"Enter recipient's name: \")\n",
    "    recipient_email = input(\"Enter recipient's email: \")\n",
    "    location = input(\"Enter city or pin code to search for doctors nearby: \")\n",
    "\n",
    "    # === STEP 1: Use RAG Agent for Diagnosis ===\n",
    "    start = time.time()\n",
    "    query = (\n",
    "        \"A 12-year-old child is making careless mistakes in schoolwork and struggles to maintain attention. \"\n",
    "        \"What might be the issue?\"\n",
    "    )\n",
    "    rag_response = rag_chain.invoke(query)[\"result\"]\n",
    "    diagnosis = rag_response.strip()\n",
    "    log_time(\"Diagnosis RAG Query\", start)\n",
    "\n",
    "    print(\"\\n--- Diagnosis ---\\n\")\n",
    "    print(diagnosis)\n",
    "\n",
    "    # === STEP 2: Get Doctor Specialties ===\n",
    "    start = time.time()\n",
    "    specialties = get_doctor_specialty(diagnosis, rag_chain)\n",
    "    log_time(\"Get Doctor Specialties\", start)\n",
    "\n",
    "    print(\"\\n--- Doctor Specialties Identified ---\\n\")\n",
    "    print(specialties)\n",
    "\n",
    "    # === STEP 3: Web Search (Optional) ===\n",
    "    start = time.time()\n",
    "    web_output = search_web(diagnosis)\n",
    "    log_time(\"Web Search\", start)\n",
    "\n",
    "    print(\"\\n--- Web Search Output ---\\n\")\n",
    "    print(web_output)\n",
    "\n",
    "    # === STEP 4: Summarize ===\n",
    "    start = time.time()\n",
    "    combined = f\"Diagnosis:\\n{diagnosis}\\n\\nWeb Results:\\n{web_output}\"\n",
    "    summary = summarize_text(combined)\n",
    "    log_time(\"Summary Generation\", start)\n",
    "\n",
    "    # === STEP 5: Personalize Summary ===\n",
    "    personalized_summary = (\n",
    "        f\"Dear {recipient_name},\\n\\n\"\n",
    "        + summary.replace(\"[Your Name]\", sender_name).replace(\"[Recipient]\", recipient_name)\n",
    "    )\n",
    "\n",
    "    # === STEP 6: Normalize & Search for Doctors ===\n",
    "    start = time.time()\n",
    "    normalized_specialties = normalize_roles(specialties)\n",
    "    print(\"\\n--- Normalized Doctor Specialties for Practo ---\\n\")\n",
    "    print(normalized_specialties)\n",
    "\n",
    "    doctor_info_links = search_multiple_doctors(specialties, location)\n",
    "    log_time(\"Doctor Search\", start)\n",
    "\n",
    "    # === STEP 7: Final Email Body ===\n",
    "    final_email_body = f\"\"\"{personalized_summary}\n",
    "\n",
    "--- Doctor Recommendation ---\n",
    "Specialist(s) recommended: {', '.join(specialties)}\n",
    "\n",
    "{doctor_info_links}\n",
    "\"\"\"\n",
    "\n",
    "    # === STEP 8: Send Email ===\n",
    "    start = time.time()\n",
    "    send_email(\n",
    "        \"Child Mental Health Assessment Summary & Doctor Recommendation\",\n",
    "        final_email_body,\n",
    "        recipient_email,\n",
    "    )\n",
    "    log_time(\"Email Sent\", start)\n",
    "\n",
    "    # === Optional Preview ===\n",
    "    print(\"\\n✅ Email Sent! --- Summary Preview Below ---\\n\")\n",
    "    print(summary)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e89140-3e21-4e9a-8d72-08619a2cb0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57299975-81fc-4f7e-9715-18d6bc8ddd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF Path: D:\\Surya\\Myworkspace\\Project\\rag-mcp-agents\\data\\MentalHealth.pdf\n",
      "Absolute Path: D:\\Surya\\Myworkspace\\Project\\rag-mcp-agents\\data\\MentalHealth.pdf\n",
      "Exists: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Surya\\Myworkspace\\Project\\rag-mcp-agents\\agents\\summarizer_agent.py:5: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=MODEL_NAME)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG already initialized – using cached instance\n",
      "🔄 Loading embeddings...\n",
      "✅ Loading existing FAISS vector store from disk...\n",
      "✅ Ollama LLM loaded\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter recipient's name:  Priya Patel\n",
      "Enter recipient's email:  surajsuresh1509@gmail.com\n",
      "Enter city or pin code to search for doctors nearby:  mumbai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded cached diagnosis\n",
      "\n",
      "--- Diagnosis ---\n",
      "\n",
      "The 12-year-old child's symptoms suggest Attention Deficit Hyperactivity Disorder (ADHD). The child may have difficulty paying attention to details, sustaining attention to tasks or activities, following through on instructions, organizing tasks and activities, and playing or engaging in leisure activities quietly. These are common symptoms of ADHD as indicated by the Vanderbilt ADHD Teacher Rating Scale. It is recommended to consult a healthcare professional for a proper diagnosis and treatment plan.\n",
      "✅ Loaded cached specialties\n",
      "🌐 Searching Duckduckgo...\n",
      "🔍 Performing new search using DuckDuckGo\n",
      "\n",
      "--- Web Search Output ---\n",
      "\n",
      "No relevant results found.\n",
      "\n",
      "--- Normalized Doctor Specialties for Practo ---\n",
      "\n",
      "['Psychiatrist', 'neurologist', 'pediatrician', 'Psychologist']\n",
      "Extracted specialties: ['pediatrician', 'neurologist', 'Psychiatrist', 'Psychologist']\n",
      "Normalized specialties: ['Psychiatrist', 'neurologist', 'pediatrician', 'Psychologist']\n",
      "🔎 Searching Practo for each specialty...\n",
      "🔎 Searching: Psychiatrist in mumbai\n",
      "🔎 Searching: neurologist in mumbai\n",
      "🔎 Searching: pediatrician in mumbai\n",
      "🔎 Searching: Psychologist in mumbai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_28832\\2719092943.py:91: RuntimeWarning: coroutine 'search_doctor' was never awaited\n",
      "  search_result = search_doctor(location, spec)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Email sent successfully.\n",
      "\n",
      "✅ Email Sent! --- Summary Preview Below ---\n",
      "\n",
      " Hi there,\n",
      "\n",
      "I've been analyzing some health-related information regarding your child. The symptoms observed suggest that your child may have Attention Deficit Hyperactivity Disorder (ADHD). This condition often makes it hard for children to focus on tasks, follow instructions, and engage in quiet activities.\n",
      "\n",
      "To confirm this diagnosis and discuss the best treatment options, I recommend consulting a healthcare professional as soon as possible. They can provide a thorough evaluation based on their expertise.\n",
      "\n",
      "Please let me know if you have any questions or need further assistance.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from agents.rag_agent import build_rag_agent\n",
    "from agents.web_agent import search_web\n",
    "from agents.summarizer_agent import summarize_text\n",
    "from agents.email_agent import send_email\n",
    "from agents.doctor_search_agent import get_doctor_specialty, search_doctor, normalize_roles\n",
    "from config import SENDER_NAME\n",
    "\n",
    "\n",
    "# === CACHE SETUP ===\n",
    "CACHE_FILE = \"cache_session.json\"\n",
    "\n",
    "def load_cache():\n",
    "    return json.load(open(CACHE_FILE)) if os.path.exists(CACHE_FILE) else {}\n",
    "\n",
    "def save_cache(data):\n",
    "    with open(CACHE_FILE, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "cache = load_cache()\n",
    "\n",
    "# === Build RAG Once ===\n",
    "print(\"RAG already initialized – using cached instance\")\n",
    "rag_chain = build_rag_agent()\n",
    "\n",
    "# === USER INPUT ===\n",
    "recipient_name = input(\"Enter recipient's name: \")\n",
    "recipient_email = input(\"Enter recipient's email: \")\n",
    "location = input(\"Enter city or pin code to search for doctors nearby: \")\n",
    "\n",
    "query = (\n",
    "    \"A 12-year-old child is making careless mistakes in schoolwork and struggles to maintain attention. \"\n",
    "    \"What might be the issue?\"\n",
    ")\n",
    "\n",
    "# === STEP 1: Diagnosis with cache ===\n",
    "if \"diagnosis\" not in cache:\n",
    "    print(\"💡 Running diagnosis...\")\n",
    "    rag_response = rag_chain.invoke(query)[\"result\"]\n",
    "    cache[\"diagnosis\"] = rag_response.strip()\n",
    "    save_cache(cache)\n",
    "else:\n",
    "    print(\"✅ Loaded cached diagnosis\")\n",
    "\n",
    "diagnosis = cache[\"diagnosis\"]\n",
    "print(\"\\n--- Diagnosis ---\\n\")\n",
    "print(diagnosis)\n",
    "\n",
    "# === STEP 2: Doctor Specialties with cache ===\n",
    "if \"specialties\" not in cache:\n",
    "    print(\"💡 Extracting specialties...\")\n",
    "    raw_roles = get_doctor_specialty(diagnosis, rag_chain)\n",
    "    cache[\"specialties\"] = raw_roles\n",
    "    save_cache(cache)\n",
    "else:\n",
    "    print(\"✅ Loaded cached specialties\")\n",
    "\n",
    "specialties = cache[\"specialties\"]\n",
    "\n",
    "# === STEP 3: Web Search (cached inside web_agent.py) ===\n",
    "print(\"🌐 Searching Duckduckgo...\")\n",
    "web_output = search_web(diagnosis)\n",
    "print(\"\\n--- Web Search Output ---\\n\")\n",
    "print(web_output)\n",
    "\n",
    "# === STEP 4: Summarize diagnosis + web ===\n",
    "combined = f\"Diagnosis:\\n{diagnosis}\\n\\nWeb Results:\\n{web_output}\"\n",
    "summary = summarize_text(combined)\n",
    "\n",
    "# === STEP 5: Personalize Email Body ===\n",
    "sender_name = SENDER_NAME\n",
    "personalized_summary = f\"Dear {recipient_name},\\n\\n\" + summary.replace(\"[Your Name]\", sender_name)\n",
    "\n",
    "# === STEP 6: Normalize + Search Doctor Info ===\n",
    "normalized_specialties = list(set(normalize_roles(specialties)))\n",
    "print(\"\\n--- Normalized Doctor Specialties for Practo ---\\n\")\n",
    "print(normalized_specialties)\n",
    "print(\"Extracted specialties:\", specialties)\n",
    "print(\"Normalized specialties:\", normalized_specialties)\n",
    "\n",
    "# Unique cache key for combination of specialties and location\n",
    "cache_key = f\"{','.join(normalized_specialties)}@{location}\"\n",
    "\n",
    "if cache_key not in cache:\n",
    "    print(\"🔎 Searching Practo for each specialty...\")\n",
    "    results = []\n",
    "    for spec in normalized_specialties:\n",
    "        try:\n",
    "            print(f\"🔎 Searching: {spec} in {location}\")\n",
    "            search_result = search_doctor(location, spec)\n",
    "            if \"❌\" not in search_result.lower():\n",
    "                results.append(f\"\\n🩺 **{spec.title()}** →\\n{search_result}\")\n",
    "            else:\n",
    "                results.append(f\"\\n❌ **{spec.title()}** → Not found\\n{search_result}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            results.append(f\"\\n❌ **{spec.title()}** → Error: {e}\\n\")\n",
    "    doctor_info_links = \"\\n\".join(results)\n",
    "    cache[cache_key] = doctor_info_links\n",
    "    save_cache(cache)\n",
    "else:\n",
    "    print(\"✅ Loaded cached doctor search results\")\n",
    "    doctor_info_links = cache[cache_key]\n",
    "\n",
    "# === STEP 7: Final Email Body ===\n",
    "final_email_body = f\"\"\"{personalized_summary}\n",
    "\n",
    "--- Doctor Recommendation ---\n",
    "Specialist(s) recommended: {', '.join(specialties)}\n",
    "\n",
    "{doctor_info_links}\n",
    "\"\"\"\n",
    "\n",
    "# === STEP 8: Send Email ===\n",
    "send_email(\"Child Mental Health Assessment Summary & Doctor Recommendation\", final_email_body, recipient_email)\n",
    "\n",
    "# === Optional Preview ===\n",
    "print(\"\\n✅ Email Sent! --- Summary Preview Below ---\\n\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da48713-6a04-4611-9619-13d378e7fc3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44793fe4-fac0-4d86-8fbb-ab1d8c210997",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd80250-07a8-48bd-8e3d-b1b398251c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.doctor_search_agent import search_doctor\n",
    "\n",
    "output = search_doctor(\"Child Psychologist, Pediatrician\", \"Mumbai\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cf0062-22d7-4490-bd4a-f089a2296bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import doctor_search_agent\n",
    "print(dir(doctor_search_agent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045ee0c7-1a0b-4133-a6fa-a81a58258ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "url = \"https://www.practo.com/mumbai/doctors?specialization=Psychologist\"\n",
    "driver.get(url)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "# now parse doctor_cards like before\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7ac241-2178-4478-a1aa-f2c617210355",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75c1af3-5c70-40b1-b100-443bef3413cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824cc5ee-da06-4c0e-bc5b-6b1c13e29438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Set Chrome options\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")  # Run in headless mode (no UI)\n",
    "\n",
    "# Set the path to chromedriver\n",
    "service = Service(\"C:/WebDrivers/chromedriver.exe\")  # use forward slashes or double backslashes\n",
    "\n",
    "# Launch browser\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Open the URL\n",
    "url = \"https://www.practo.com/mumbai/doctors?specialization=Psychologist\"\n",
    "driver.get(url)\n",
    "\n",
    "# Extract HTML\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Do your parsing here\n",
    "print(soup.title.text)  # Example: Print page title\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c7abce-0918-4a27-954c-2cf11c858036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.doctor_search_agent import search_doctor\n",
    "\n",
    "print(search_doctor(\"Psychiatrist\", \"mumbai\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3983ac34-2ea5-4fa9-bc6c-f2fe078333e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install playwright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d1149c-d500-46ac-b06d-f788b1030afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from agents.rag_agent import build_rag_agent\n",
    "from agents.web_agent import search_web\n",
    "from agents.summarizer_agent import summarize_text\n",
    "from agents.email_agent import send_email\n",
    "from agents.doctor_search_agent import get_doctor_specialty, search_doctor, normalize_roles\n",
    "from config import SENDER_NAME\n",
    "\n",
    "# === CACHE SETUP ===\n",
    "CACHE_FILE = \"cache_session.json\"\n",
    "\n",
    "def load_cache():\n",
    "    return json.load(open(CACHE_FILE)) if os.path.exists(CACHE_FILE) else {}\n",
    "\n",
    "def save_cache(data):\n",
    "    with open(CACHE_FILE, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "cache = load_cache()\n",
    "\n",
    "# === Build RAG Once ===\n",
    "print(\"RAG already initialized – using cached instance\")\n",
    "rag_chain = build_rag_agent()\n",
    "\n",
    "# === USER INPUT ===\n",
    "recipient_name = input(\"Enter recipient's name: \")\n",
    "recipient_email = input(\"Enter recipient's email: \")\n",
    "location = input(\"Enter city or pin code to search for doctors nearby: \")\n",
    "\n",
    "query = (\n",
    "    \"A 12-year-old child is making careless mistakes in schoolwork and struggles to maintain attention. \"\n",
    "    \"What might be the issue?\"\n",
    ")\n",
    "\n",
    "# === STEP 1: Diagnosis with cache ===\n",
    "if \"diagnosis\" not in cache:\n",
    "    print(\"💡 Running diagnosis...\")\n",
    "    rag_response = rag_chain.invoke(query)[\"result\"]\n",
    "    cache[\"diagnosis\"] = rag_response.strip()\n",
    "    save_cache(cache)\n",
    "else:\n",
    "    print(\"✅ Loaded cached diagnosis\")\n",
    "\n",
    "diagnosis = cache[\"diagnosis\"]\n",
    "print(\"\\n--- Diagnosis ---\\n\")\n",
    "print(diagnosis)\n",
    "\n",
    "# === STEP 2: Doctor Specialties with cache ===\n",
    "if \"specialties\" not in cache:\n",
    "    print(\"💡 Extracting specialties...\")\n",
    "    raw_roles = get_doctor_specialty(diagnosis, rag_chain)\n",
    "    cleaned_roles = normalize_roles(raw_roles)\n",
    "    cache[\"specialties\"] = cleaned_roles\n",
    "    save_cache(cache)\n",
    "else:\n",
    "    print(\"✅ Loaded cached specialties\")\n",
    "\n",
    "specialties = cache[\"specialties\"]\n",
    "normalized_specialties = list(set(specialties))  # Deduplicated list\n",
    "\n",
    "# === STEP 3: Web Search ===\n",
    "print(\"🔎 Searching Google...\")\n",
    "web_output = search_web(diagnosis)\n",
    "print(\"\\n--- Web Search Output ---\\n\")\n",
    "print(web_output)\n",
    "\n",
    "# === STEP 4: Summarize diagnosis + web ===\n",
    "combined = f\"Diagnosis:\\n{diagnosis}\\n\\nWeb Results:\\n{web_output}\"\n",
    "summary = summarize_text(combined)\n",
    "\n",
    "# === STEP 5: Personalize Email Body ===\n",
    "sender_name = SENDER_NAME\n",
    "personalized_summary = f\"Dear {recipient_name},\\n\\n{summary.strip()}\\n\\nRegards,\\n{sender_name}\"\n",
    "\n",
    "# === STEP 6: Doctor Search on Practo ===\n",
    "print(\"\\n--- Normalized Doctor Specialties for Practo ---\\n\")\n",
    "print(normalized_specialties)\n",
    "\n",
    "cache_key = f\"{','.join(normalized_specialties)}@{location}\"\n",
    "\n",
    "if cache_key not in cache:\n",
    "    print(\"🔎 Searching Practo...\")\n",
    "    try:\n",
    "        doctor_info_links = search_doctor(\", \".join(normalized_specialties), location)\n",
    "    except Exception as e:\n",
    "        doctor_info_links = f\"❌ No verified doctors found. [Search manually](https://www.practo.com/search?results_for=doctor&query={','.join(normalized_specialties)}&city={location})\"\n",
    "        print(\"❌ Practo search failed:\", e)\n",
    "    cache[cache_key] = doctor_info_links\n",
    "    save_cache(cache)\n",
    "else:\n",
    "    print(\"✅ Loaded cached doctor search results\")\n",
    "    doctor_info_links = cache[cache_key]\n",
    "\n",
    "# === STEP 7: Final Email Body ===\n",
    "final_email_body = f\"\"\"{personalized_summary}\n",
    "\n",
    "--- Doctor Recommendation ---\n",
    "Specialist(s) recommended: {', '.join(normalized_specialties)}\n",
    "\n",
    "{doctor_info_links}\n",
    "\"\"\"\n",
    "\n",
    "# === STEP 8: Send Email ===\n",
    "send_email(\n",
    "    \"Child Mental Health Assessment Summary & Doctor Recommendation\",\n",
    "    final_email_body,\n",
    "    recipient_email\n",
    ")\n",
    "\n",
    "# === Optional Preview ===\n",
    "print(\"\\n✅ Email Sent! --- Summary Preview Below ---\\n\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f91a437-fced-4749-ae5b-6e87b1243b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Performing new search using DuckDuckGo\n",
      "--- Web Search Output ---\n",
      "\n",
      "Best Pediatricians Near Me in Mumbai - Practo - //duckduckgo.com/l/?uddg=https%3A%2F%2Fwww.practo.com%2Fmumbai%2Fpediatrician&rut=d59bda92456911313f4071a6ac73089d6f1dff1bb46205fa761783b5e92ec284\n",
      "\n",
      "Top 10 Pediatrician in Mumbai, Child Specialist in Mumbai, Top 10 ... - //duckduckgo.com/l/?uddg=https%3A%2F%2Fwww.365doctor.in%2Fpediatrician%2Din%2Dmumbai&rut=f8c19c05056bc123b5bb72d086d8c3425eaa396350fad2f8258e3df1223de0fb\n",
      "\n",
      "The Children's Hospital in Mumbai: Best Care for Your Child - //duckduckgo.com/l/?uddg=https%3A%2F%2Fwww.thechildrenshospitalmumbai.com%2F&rut=339ee5be15d6cb1a2e5e686658d4218c9a61291e8fdc6430f6462986e592403d\n",
      "\n",
      "Pediatrician in Mumbai - Best Child Specialist - Top List - Book ... - //duckduckgo.com/l/?uddg=https%3A%2F%2Fwww.lybrate.com%2Fmumbai%2Fpediatrician&rut=a34db981f023adba630f24c95f31ee0c81001c65c451b1bb43749a58a700d5ba\n",
      "\n",
      "Top 10 Pediatricians in Mumbai - Best Child Specialist - //duckduckgo.com/l/?uddg=https%3A%2F%2Fwww.docindia.org%2Findia%2Fmh%2Fmumbai%2Fpediatrics&rut=94931ea90127f6c12638fa08e6b33180cebdf900cb1b5ac1ec24e62a0ba8b5c0\n"
     ]
    }
   ],
   "source": [
    "from agents.web_agent import search_web\n",
    "\n",
    "result = search_web(\"pediatricians in Mumbai\")\n",
    "print(\"--- Web Search Output ---\\n\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4f2bba-7cdb-4348-b6f8-39529c56aad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62554338-1b4b-4825-aff2-e79c4ef1ced2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\anaconda3\\lib\\site-packages (4.53.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3fs 2025.3.2 requires fsspec==2025.3.2.*, but you have fsspec 2025.3.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting peft\n",
      "  Downloading peft-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.9.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.46.1-py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.33.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\anaconda3\\lib\\site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from peft) (2.7.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.10)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft) (72.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.18.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.7.14)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading peft-0.16.0-py3-none-any.whl (472 kB)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading accelerate-1.9.0-py3-none-any.whl (367 kB)\n",
      "Downloading bitsandbytes-0.46.1-py3-none-win_amd64.whl (72.2 MB)\n",
      "   ---------------------------------------- 0.0/72.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/72.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.8/72.2 MB 2.7 MB/s eta 0:00:27\n",
      "    --------------------------------------- 1.6/72.2 MB 3.0 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 2.4/72.2 MB 3.2 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 3.4/72.2 MB 3.5 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 4.2/72.2 MB 3.6 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 5.0/72.2 MB 3.7 MB/s eta 0:00:19\n",
      "   --- ------------------------------------ 6.0/72.2 MB 3.8 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 7.1/72.2 MB 3.9 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 7.6/72.2 MB 3.9 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 8.1/72.2 MB 3.6 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 9.2/72.2 MB 3.7 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 10.0/72.2 MB 3.7 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 11.0/72.2 MB 3.8 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 11.8/72.2 MB 3.8 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 12.6/72.2 MB 3.8 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 13.6/72.2 MB 3.8 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 14.4/72.2 MB 3.8 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 15.2/72.2 MB 3.8 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 16.0/72.2 MB 3.8 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 16.8/72.2 MB 3.9 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 17.6/72.2 MB 3.8 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 18.6/72.2 MB 3.8 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 19.4/72.2 MB 3.9 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 20.4/72.2 MB 3.9 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 21.2/72.2 MB 3.9 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 22.0/72.2 MB 3.9 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 22.8/72.2 MB 3.9 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 23.6/72.2 MB 3.9 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 24.6/72.2 MB 3.9 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 25.4/72.2 MB 3.9 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 26.2/72.2 MB 3.9 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 27.0/72.2 MB 3.9 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 28.0/72.2 MB 3.9 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 28.8/72.2 MB 3.9 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 29.6/72.2 MB 3.9 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 30.4/72.2 MB 3.9 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 31.2/72.2 MB 3.9 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 32.0/72.2 MB 3.9 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 32.8/72.2 MB 3.9 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 33.6/72.2 MB 3.9 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 34.6/72.2 MB 3.9 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 35.1/72.2 MB 3.9 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 36.2/72.2 MB 3.9 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 37.0/72.2 MB 3.9 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 38.0/72.2 MB 3.9 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 38.8/72.2 MB 3.9 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 39.6/72.2 MB 3.9 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 40.4/72.2 MB 3.9 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 41.2/72.2 MB 3.9 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 41.9/72.2 MB 3.9 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 43.0/72.2 MB 3.9 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 43.8/72.2 MB 3.9 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 44.6/72.2 MB 3.9 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 45.6/72.2 MB 3.9 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 46.4/72.2 MB 3.9 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 47.2/72.2 MB 3.9 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 48.0/72.2 MB 3.9 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 49.0/72.2 MB 3.9 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 49.5/72.2 MB 3.9 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 50.6/72.2 MB 3.9 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 51.4/72.2 MB 3.9 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 52.2/72.2 MB 3.9 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 53.2/72.2 MB 3.9 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 54.0/72.2 MB 3.9 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 54.8/72.2 MB 3.9 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 55.6/72.2 MB 3.9 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 56.4/72.2 MB 3.9 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 57.1/72.2 MB 3.9 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 58.2/72.2 MB 3.9 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 59.0/72.2 MB 3.9 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 59.8/72.2 MB 3.9 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 60.6/72.2 MB 3.9 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 61.3/72.2 MB 3.9 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 62.4/72.2 MB 3.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 63.2/72.2 MB 3.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 64.0/72.2 MB 3.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 64.7/72.2 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 65.5/72.2 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 66.3/72.2 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 67.4/72.2 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 68.2/72.2 MB 3.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 68.9/72.2 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 70.0/72.2 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  70.8/72.2 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  71.6/72.2 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  72.1/72.2 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  72.1/72.2 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 72.2/72.2 MB 3.8 MB/s eta 0:00:00\n",
      "Installing collected packages: multiprocess, fsspec, bitsandbytes, accelerate, datasets, peft\n",
      "\n",
      "   ---------------------------------------- 0/6 [multiprocess]\n",
      "   ---------------------------------------- 0/6 [multiprocess]\n",
      "   ---------------------------------------- 0/6 [multiprocess]\n",
      "   ---------------------------------------- 0/6 [multiprocess]\n",
      "  Attempting uninstall: fsspec\n",
      "   ---------------------------------------- 0/6 [multiprocess]\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "   ---------------------------------------- 0/6 [multiprocess]\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "   ---------------------------------------- 0/6 [multiprocess]\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "   ---------------------------------------- 0/6 [multiprocess]\n",
      "   ------ --------------------------------- 1/6 [fsspec]\n",
      "   ------ --------------------------------- 1/6 [fsspec]\n",
      "   ------ --------------------------------- 1/6 [fsspec]\n",
      "   ------ --------------------------------- 1/6 [fsspec]\n",
      "   ------ --------------------------------- 1/6 [fsspec]\n",
      "   ------ --------------------------------- 1/6 [fsspec]\n",
      "   ------ --------------------------------- 1/6 [fsspec]\n",
      "   ------------- -------------------------- 2/6 [bitsandbytes]\n",
      "   ------------- -------------------------- 2/6 [bitsandbytes]\n",
      "   ------------- -------------------------- 2/6 [bitsandbytes]\n",
      "   ------------- -------------------------- 2/6 [bitsandbytes]\n",
      "   ------------- -------------------------- 2/6 [bitsandbytes]\n",
      "   ------------- -------------------------- 2/6 [bitsandbytes]\n",
      "   ------------- -------------------------- 2/6 [bitsandbytes]\n",
      "   ------------- -------------------------- 2/6 [bitsandbytes]\n",
      "   ------------- -------------------------- 2/6 [bitsandbytes]\n",
      "   ------------- -------------------------- 2/6 [bitsandbytes]\n",
      "   ------------- -------------------------- 2/6 [bitsandbytes]\n",
      "   ------------- -------------------------- 2/6 [bitsandbytes]\n",
      "   ------------- -------------------------- 2/6 [bitsandbytes]\n",
      "   ------------- -------------------------- 2/6 [bitsandbytes]\n",
      "   ------------- -------------------------- 2/6 [bitsandbytes]\n",
      "   ------------- -------------------------- 2/6 [bitsandbytes]\n",
      "   ------------- -------------------------- 2/6 [bitsandbytes]\n",
      "   ------------- -------------------------- 2/6 [bitsandbytes]\n",
      "   -------------------- ------------------- 3/6 [accelerate]\n",
      "   -------------------- ------------------- 3/6 [accelerate]\n",
      "   -------------------- ------------------- 3/6 [accelerate]\n",
      "   -------------------- ------------------- 3/6 [accelerate]\n",
      "   -------------------- ------------------- 3/6 [accelerate]\n",
      "   -------------------- ------------------- 3/6 [accelerate]\n",
      "   -------------------- ------------------- 3/6 [accelerate]\n",
      "   -------------------- ------------------- 3/6 [accelerate]\n",
      "   -------------------- ------------------- 3/6 [accelerate]\n",
      "   -------------------- ------------------- 3/6 [accelerate]\n",
      "   -------------------------- ------------- 4/6 [datasets]\n",
      "   -------------------------- ------------- 4/6 [datasets]\n",
      "   -------------------------- ------------- 4/6 [datasets]\n",
      "   -------------------------- ------------- 4/6 [datasets]\n",
      "   -------------------------- ------------- 4/6 [datasets]\n",
      "   -------------------------- ------------- 4/6 [datasets]\n",
      "   -------------------------- ------------- 4/6 [datasets]\n",
      "   -------------------------- ------------- 4/6 [datasets]\n",
      "   -------------------------- ------------- 4/6 [datasets]\n",
      "   -------------------------- ------------- 4/6 [datasets]\n",
      "   -------------------------- ------------- 4/6 [datasets]\n",
      "   -------------------------- ------------- 4/6 [datasets]\n",
      "   --------------------------------- ------ 5/6 [peft]\n",
      "   --------------------------------- ------ 5/6 [peft]\n",
      "   --------------------------------- ------ 5/6 [peft]\n",
      "   --------------------------------- ------ 5/6 [peft]\n",
      "   --------------------------------- ------ 5/6 [peft]\n",
      "   --------------------------------- ------ 5/6 [peft]\n",
      "   --------------------------------- ------ 5/6 [peft]\n",
      "   --------------------------------- ------ 5/6 [peft]\n",
      "   --------------------------------- ------ 5/6 [peft]\n",
      "   --------------------------------- ------ 5/6 [peft]\n",
      "   --------------------------------- ------ 5/6 [peft]\n",
      "   --------------------------------- ------ 5/6 [peft]\n",
      "   --------------------------------- ------ 5/6 [peft]\n",
      "   ---------------------------------------- 6/6 [peft]\n",
      "\n",
      "Successfully installed accelerate-1.9.0 bitsandbytes-0.46.1 datasets-4.0.0 fsspec-2025.3.0 multiprocess-0.70.16 peft-0.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers peft datasets accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "089488cd-3e72-4ec5-83bf-485a610321df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "from datasets import load_dataset, Dataset\n",
    "import json\n",
    "\n",
    "# Load your local file\n",
    "with open(\"C:/Users/user/Downloads/mental_health_qa.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert to HuggingFace dataset\n",
    "dataset = Dataset.from_list(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c715d5f-dc5a-4526-a591-5771a964b98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0852f147fb8f44328bf81ed61b153d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub\\models--tiiuae--falcon-rw-1b. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fd8dcee7a5461e94e02f2285d8deb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef5fbb8871de4f5d8a9fcfc781c68eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3845587e5ca446fb7003a3ddc2f6e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792785534289489ab572b232c680f0d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1ba339ce4047109ae6a32212010fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers and GPU quantization are unavailable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7499128cf34b07ad4ff4ba2f7ee0f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.62G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.hf.co/repos/2e/3a/2e3a78ac75bfe23c7017cb7792215cef508b32914302fce14d30c8b3b95f46fd/3a0d68f0309c8f7ec913f51edf8bf2eca849477c9f53db727f49ffa2f6019251?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1753208154&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MzIwODE1NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8yZS8zYS8yZTNhNzhhYzc1YmZlMjNjNzAxN2NiNzc5MjIxNWNlZjUwOGIzMjkxNDMwMmZjZTE0ZDMwYzhiM2I5NWY0NmZkLzNhMGQ2OGYwMzA5YzhmN2VjOTEzZjUxZWRmOGJmMmVjYTg0OTQ3N2M5ZjUzZGI3MjdmNDlmZmEyZjYwMTkyNTE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=UMJr0hNSoSGzQDgI%7EyK%7Ep3bZAGYGnMB6KNl6Zunvnetf7PXkbGm%7E8nxMJQ29OJ7ky54fdH2G0QOMG2SJhttkc6Sgzt8OTyEr7IPvM5HYT37t7J4JM%7EDUQF%7EuCWK4jo6LDq11CWO9zWNorFxi0wmcekhJx%7Ezn6gPYwjZlkJ6Jghdu3o4J0YIQL3uaR-gnczHe3fdT4tMNkO%7EMiZlKt71qKKnTy-TWwOPYGB4Lmp76bIxxUOvVuhYFb4v7orCZlI85UA41hi1aBDPypNejkbxpWYtBWtmMMW-VtnjDhXnFNEfC8MH24U-6X6pXRh9-3ihL6P7X5qwrGLUiHd2sL89p3w__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5081e154559410b859760e69597ba8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   2%|1         | 52.4M/2.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d36e7b0ee74f8e99b46116fa0a9b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.62G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "quant_type must be nf4 on CPU, got fp4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtiiuae/falcon-rw-1b\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[1;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m      9\u001b[0m     model_name,\n\u001b[0;32m     10\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     load_in_4bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     12\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m prepare_model_for_kbit_training(model)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:600\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39msub_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    599\u001b[0m         config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_text_config()\n\u001b[1;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    601\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    602\u001b[0m     )\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    606\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:311\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    313\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:4839\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4830\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[0;32m   4832\u001b[0m     (\n\u001b[0;32m   4833\u001b[0m         model,\n\u001b[0;32m   4834\u001b[0m         missing_keys,\n\u001b[0;32m   4835\u001b[0m         unexpected_keys,\n\u001b[0;32m   4836\u001b[0m         mismatched_keys,\n\u001b[0;32m   4837\u001b[0m         offload_index,\n\u001b[0;32m   4838\u001b[0m         error_msgs,\n\u001b[1;32m-> 4839\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_load_pretrained_model(\n\u001b[0;32m   4840\u001b[0m         model,\n\u001b[0;32m   4841\u001b[0m         state_dict,\n\u001b[0;32m   4842\u001b[0m         checkpoint_files,\n\u001b[0;32m   4843\u001b[0m         pretrained_model_name_or_path,\n\u001b[0;32m   4844\u001b[0m         ignore_mismatched_sizes\u001b[38;5;241m=\u001b[39mignore_mismatched_sizes,\n\u001b[0;32m   4845\u001b[0m         sharded_metadata\u001b[38;5;241m=\u001b[39msharded_metadata,\n\u001b[0;32m   4846\u001b[0m         device_map\u001b[38;5;241m=\u001b[39mdevice_map,\n\u001b[0;32m   4847\u001b[0m         disk_offload_folder\u001b[38;5;241m=\u001b[39moffload_folder,\n\u001b[0;32m   4848\u001b[0m         offload_state_dict\u001b[38;5;241m=\u001b[39moffload_state_dict,\n\u001b[0;32m   4849\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mtorch_dtype,\n\u001b[0;32m   4850\u001b[0m         hf_quantizer\u001b[38;5;241m=\u001b[39mhf_quantizer,\n\u001b[0;32m   4851\u001b[0m         keep_in_fp32_regex\u001b[38;5;241m=\u001b[39mkeep_in_fp32_regex,\n\u001b[0;32m   4852\u001b[0m         device_mesh\u001b[38;5;241m=\u001b[39mdevice_mesh,\n\u001b[0;32m   4853\u001b[0m         key_mapping\u001b[38;5;241m=\u001b[39mkey_mapping,\n\u001b[0;32m   4854\u001b[0m         weights_only\u001b[38;5;241m=\u001b[39mweights_only,\n\u001b[0;32m   4855\u001b[0m     )\n\u001b[0;32m   4857\u001b[0m \u001b[38;5;66;03m# record tp degree the model sharded to\u001b[39;00m\n\u001b[0;32m   4858\u001b[0m model\u001b[38;5;241m.\u001b[39m_tp_size \u001b[38;5;241m=\u001b[39m tp_size\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:5302\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[1;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[0;32m   5299\u001b[0m         args_list \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mtqdm(args_list, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading checkpoint shards\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5301\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m args_list:\n\u001b[1;32m-> 5302\u001b[0m         _error_msgs, disk_offload_index, cpu_offload_index \u001b[38;5;241m=\u001b[39m load_shard_file(args)\n\u001b[0;32m   5303\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m _error_msgs\n\u001b[0;32m   5305\u001b[0m \u001b[38;5;66;03m# Adjust offloaded weights name and save if needed\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:933\u001b[0m, in \u001b[0;36mload_shard_file\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    931\u001b[0m \u001b[38;5;66;03m# Skip it with fsdp on ranks other than 0\u001b[39;00m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized):\n\u001b[1;32m--> 933\u001b[0m     disk_offload_index, cpu_offload_index \u001b[38;5;241m=\u001b[39m _load_state_dict_into_meta_model(\n\u001b[0;32m    934\u001b[0m         model_to_load,\n\u001b[0;32m    935\u001b[0m         state_dict,\n\u001b[0;32m    936\u001b[0m         shard_file,\n\u001b[0;32m    937\u001b[0m         expected_keys,\n\u001b[0;32m    938\u001b[0m         reverse_key_renaming_mapping,\n\u001b[0;32m    939\u001b[0m         device_map\u001b[38;5;241m=\u001b[39mdevice_map,\n\u001b[0;32m    940\u001b[0m         disk_offload_folder\u001b[38;5;241m=\u001b[39mdisk_offload_folder,\n\u001b[0;32m    941\u001b[0m         disk_offload_index\u001b[38;5;241m=\u001b[39mdisk_offload_index,\n\u001b[0;32m    942\u001b[0m         cpu_offload_folder\u001b[38;5;241m=\u001b[39mcpu_offload_folder,\n\u001b[0;32m    943\u001b[0m         cpu_offload_index\u001b[38;5;241m=\u001b[39mcpu_offload_index,\n\u001b[0;32m    944\u001b[0m         hf_quantizer\u001b[38;5;241m=\u001b[39mhf_quantizer,\n\u001b[0;32m    945\u001b[0m         is_safetensors\u001b[38;5;241m=\u001b[39mis_offloaded_safetensors,\n\u001b[0;32m    946\u001b[0m         keep_in_fp32_regex\u001b[38;5;241m=\u001b[39mkeep_in_fp32_regex,\n\u001b[0;32m    947\u001b[0m         unexpected_keys\u001b[38;5;241m=\u001b[39munexpected_keys,\n\u001b[0;32m    948\u001b[0m         device_mesh\u001b[38;5;241m=\u001b[39mdevice_mesh,\n\u001b[0;32m    949\u001b[0m     )\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m error_msgs, disk_offload_index, cpu_offload_index\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:848\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[1;34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_regex, unexpected_keys, device_mesh)\u001b[0m\n\u001b[0;32m    845\u001b[0m     _load_parameter_into_model(model, param_name, param\u001b[38;5;241m.\u001b[39mto(param_device))\n\u001b[0;32m    847\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 848\u001b[0m     hf_quantizer\u001b[38;5;241m.\u001b[39mcreate_quantized_param(\n\u001b[0;32m    849\u001b[0m         model, param, param_name, param_device, state_dict, unexpected_keys\n\u001b[0;32m    850\u001b[0m     )\n\u001b[0;32m    851\u001b[0m     \u001b[38;5;66;03m# For quantized modules with FSDP/DeepSpeed Stage 3, we need to quantize the parameter on the GPU\u001b[39;00m\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# and then cast it to CPU to avoid excessive memory usage on each GPU\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# in comparison to the sharded model across GPUs.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_fsdp_enabled() \u001b[38;5;129;01mor\u001b[39;00m is_deepspeed_zero3_enabled():\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\quantizers\\quantizer_bnb_4bit.py:250\u001b[0m, in \u001b[0;36mBnb4BitHfQuantizer.create_quantized_param\u001b[1;34m(self, model, param_value, param_name, target_device, state_dict, unexpected_keys)\u001b[0m\n\u001b[0;32m    247\u001b[0m         new_value \u001b[38;5;241m=\u001b[39m new_value\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    249\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m old_value\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[1;32m--> 250\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m bnb\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mParams4bit(new_value, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mto(target_device)\n\u001b[0;32m    252\u001b[0m module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m new_value\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bitsandbytes\\nn\\modules.py:336\u001b[0m, in \u001b[0;36mParams4bit.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    333\u001b[0m device, dtype, non_blocking, convert_to_format \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39m_parse_to(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m device\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbnb_quantized:\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_quantize(device)\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bitsandbytes\\nn\\modules.py:295\u001b[0m, in \u001b[0;36mParams4bit._quantize\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_quantize\u001b[39m(\u001b[38;5;28mself\u001b[39m, device):\n\u001b[0;32m    294\u001b[0m     w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m--> 295\u001b[0m     w_4bit, quant_state \u001b[38;5;241m=\u001b[39m bnb\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mquantize_4bit(\n\u001b[0;32m    296\u001b[0m         w,\n\u001b[0;32m    297\u001b[0m         blocksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize,\n\u001b[0;32m    298\u001b[0m         compress_statistics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompress_statistics,\n\u001b[0;32m    299\u001b[0m         quant_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_type,\n\u001b[0;32m    300\u001b[0m         quant_storage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_storage,\n\u001b[0;32m    301\u001b[0m     )\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m w_4bit\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_state \u001b[38;5;241m=\u001b[39m quant_state\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bitsandbytes\\functional.py:1008\u001b[0m, in \u001b[0;36mquantize_4bit\u001b[1;34m(A, absmax, out, blocksize, compress_statistics, quant_type, quant_storage)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Quantize tensor A in blocks of 4-bit values.\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \n\u001b[0;32m    985\u001b[0m \u001b[38;5;124;03mQuantizes tensor A by dividing it into blocks which are independently quantized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;124;03m    - [`QuantState`]: The state object used to undo the quantization.\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1006\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m-> 1008\u001b[0m _out, _absmax \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mbitsandbytes\u001b[38;5;241m.\u001b[39mquantize_4bit\u001b[38;5;241m.\u001b[39mdefault(\n\u001b[0;32m   1009\u001b[0m     A,\n\u001b[0;32m   1010\u001b[0m     blocksize,\n\u001b[0;32m   1011\u001b[0m     quant_type,\n\u001b[0;32m   1012\u001b[0m     quant_storage,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[0;32m   1015\u001b[0m code \u001b[38;5;241m=\u001b[39m get_4bit_type(quant_type, device\u001b[38;5;241m=\u001b[39mA\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compress_statistics:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_ops.py:756\u001b[0m, in \u001b[0;36mOpOverload.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_compile.py:51\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[0;32m     49\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m disable_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    836\u001b[0m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback))\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 838\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    840\u001b[0m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\library.py:719\u001b[0m, in \u001b[0;36m_impl.<locals>.register_.<locals>.func_no_dynamo\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39m_disable_dynamo\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunc_no_dynamo\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bitsandbytes\\backends\\cpu\\ops.py:98\u001b[0m, in \u001b[0;36m_\u001b[1;34m(A, blocksize, quant_type, quant_storage)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;129m@register_kernel\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbitsandbytes::quantize_4bit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_\u001b[39m(\n\u001b[0;32m     95\u001b[0m     A: torch\u001b[38;5;241m.\u001b[39mTensor, blocksize: \u001b[38;5;28mint\u001b[39m, quant_type: \u001b[38;5;28mstr\u001b[39m, quant_storage: torch\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m     96\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m     97\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_check_is_size(blocksize)\n\u001b[1;32m---> 98\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_check(quant_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnf4\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquant_type must be nf4 on CPU, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquant_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     99\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_check(\n\u001b[0;32m    100\u001b[0m         A\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01min\u001b[39;00m [torch\u001b[38;5;241m.\u001b[39mbfloat16, torch\u001b[38;5;241m.\u001b[39mfloat16, torch\u001b[38;5;241m.\u001b[39mfloat32],\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlockwise 4bit quantization only supports 16/32-bit floats, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    102\u001b[0m     )\n\u001b[0;32m    104\u001b[0m     n \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mnumel()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:1660\u001b[0m, in \u001b[0;36m_check\u001b[1;34m(cond, message)\u001b[0m\n\u001b[0;32m   1645\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check\u001b[39m(cond, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[0;32m   1646\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Throws error containing an optional message if the specified condition\u001b[39;00m\n\u001b[0;32m   1647\u001b[0m \u001b[38;5;124;03m    is False.\u001b[39;00m\n\u001b[0;32m   1648\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1658\u001b[0m \u001b[38;5;124;03m            message. Default: ``None``\u001b[39;00m\n\u001b[0;32m   1659\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1660\u001b[0m     _check_with(\u001b[38;5;167;01mRuntimeError\u001b[39;00m, cond, message)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:1642\u001b[0m, in \u001b[0;36m_check_with\u001b[1;34m(error_type, cond, message)\u001b[0m\n\u001b[0;32m   1638\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage must be a callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1640\u001b[0m     message_evaluated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(message())\n\u001b[1;32m-> 1642\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error_type(message_evaluated)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: quant_type must be nf4 on CPU, got fp4"
     ]
    }
   ],
   "source": [
    "#Load Model in 4-bit Quantized Form\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model_name = \"tiiuae/falcon-rw-1b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    load_in_4bit=True,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b6c6210-2d48-46d2-bbc1-63ed18bf5a67",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 13\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpeft\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LoraConfig, get_peft_model\n\u001b[0;32m      4\u001b[0m lora_config \u001b[38;5;241m=\u001b[39m LoraConfig(\n\u001b[0;32m      5\u001b[0m     r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m      6\u001b[0m     lora_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     task_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCAUSAL_LM\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m )\n\u001b[1;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m get_peft_model(model, lora_config)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Apply LoRA (Parameter Efficient Fine-tuning)\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query_key_value\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aaf9db-d366-497d-a20a-f0d3467e787c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f84837-7004-470d-b94d-b02c837f24c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Data for Training\n",
    "def generate_prompt(example):\n",
    "    return f\"\"\"### Instruction:\n",
    "{example['instruction']}\n",
    "\n",
    "### Response:\n",
    "{example['output']}\"\"\"\n",
    "\n",
    "def tokenize(example):\n",
    "    return tokenizer(generate_prompt(example), truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfc6fb5-0018-41ab-97bd-7e697757491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the Model\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned_model\",\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_steps=50,\n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
